\documentclass[12pt]{article}
\usepackage[a4paper,margin=1in,footskip=0.25in]{geometry} % set margins
\usepackage[portuguese]{babel}
\usepackage[utf8]{inputenc}
\usepackage[hidelinks]{hyperref} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}    % needed for include graphics
\usepackage{subfigure}   % add subfigures
\usepackage{indentfirst}
\usepackage{float}       % needed for [H] figure placement option
\usepackage{setspace}    % needed for doublespacing
\usepackage{tikz}
\usepackage{algpseudocode}

% Macros
\renewcommand{\familydefault}{\sfdefault} % sans-serif
\newcommand{\lowtext}[1]{$_{\text{#1}}$}

% Adds ./img/ to the path of figures
\graphicspath{{./img/}}

\title{Relatório EP1 - MAC0219}
\author{Bruno Sesso, Gustavo Estrela de Matos, Lucas Sung Jun Hong}

\begin{document}
% Espaçamento duplo 
\doublespacing
\begin{titlepage}
    \vfill
    \begin{center}
        \vspace{0.5\textheight}
        \noindent
        Instituto de Matemática e Estatística \\
        EP1 - MAC0219 \\
        \vfill
        \noindent
        {\Large Cálculo do Conjunto de Mandelbrot
        em Paralelo com Pthreads e OpenMP} \\
        \bigskip
        \bigskip
        \begin{tabular}{ll}
            {\bf Professor:} & {Alfredo Goldman} \\
            {\bf Alunos:}    & {Bruno Sesso} \\
                             & {Gustavo Estrela de Matos} \\
                             & {Lucas Sung Jun Hong} \\
        \end{tabular} \\
        \vspace{\fill}
       \bigskip
        São Paulo, \today \\
       \bigskip
    \end{center}
\end{titlepage}

\pagebreak
\tableofcontents
\pagebreak

\section{Introdução}
<<<<<<< HEAD
Esse trabalho tem como objetivo implementar e analisar duas versões
paralelas de um código sequencial que é capaz de calcular o conjunto de
maldelbrot para diversas regiões do plano complexo. As duas versões do
código foram implementadas utilizando as bibliotecas OpenMP e PThreads.

Ao longo desse trabalho, iremos apresentar resultados de tempo de 
execução das diferentes implementações e suas respectivas variações.
Para isso, utilizamos a ferramenta {\em perf}, capaz de realizar 
repetições de experimentos, apresentando resultados médios e com desvio
padrão. Todos os resultados apresentados aqui foram feitos a partir de
no mínimo 10 execuções do mesmo comando.
=======
<<<<<<< HEAD
\newpage
>>>>>>> 5c630943e627b170add9c5c09bd54df8dbc9748c


    {\bf Por que é recomendado realizar mais de uma medição?} 
        Porque os resultados observados dependem do estado da máquina
        durante a execução do programa. Como testamos nossos programas
        em máquinas com um sistema operacional, rodando diversos outros
        programas ao mesmo tempo, é esperado que fatores como fila de
        processos, paginação de memória, etc, interfira no tempo de 
        execução do nosso programa. Portanto, se tiramos uma média
        de várias execuções, somos capazes de dizer aproximadamente
        o comportamento médio do programa.
\newpage
=======
Esse trabalho tem como objetivo implementar e analisar duas versões
paralelas de um código sequencial que é capaz de calcular o conjunto de
maldelbrot para diversas regiões do plano complexo. As duas versões do
código foram implementadas utilizando as bibliotecas OpenMP e PThreads.

Ao longo desse trabalho, iremos apresentar resultados de tempo de 
execução das diferentes implementações e suas respectivas variações.
Para isso, utilizamos a ferramenta {\em perf}, capaz de realizar 
repetições de experimentos, apresentando resultados médios e com desvio
padrão. Todos os resultados apresentados aqui foram feitos a partir de
no mínimo 10 execuções do mesmo comando.


    {\bf Por que é recomendado realizar mais de uma medição?} 
        Porque os resultados observados dependem do estado da máquina
        durante a execução do programa. Como testamos nossos programas
        em máquinas com um sistema operacional, rodando diversos outros
        programas ao mesmo tempo, é esperado que fatores como fila de
        processos, paginação de memória, etc, interfira no tempo de 
        execução do nosso programa. Portanto, se tiramos uma média
        de várias execuções, somos capazes de dizer aproximadamente
        o comportamento médio do programa.

>>>>>>> 4653e6a4273fd2c776556871f4cc6a77b068e828
\section{Código Sequencial}
O cálculo do conjunto em código sequencial ocorre sem nenhuma paralelização, como se houvesse apenas uma thread na implementação.

A seguir, temos a comparação de performance entre uma versão com alocação e IO, com outra sem alocação e sem IO:

Possuindo uma matriz com o tamanho pré definido libera a necessidade de acessar a memória e fazer a alocação

\newpage

\section{Código em Pthreads}
Utilizamos duas diferentes abordagens para paralelizar o código com
o uso de pthreads, tentando se aproximar ao comportamento do OpenMP e 
suas diretivas {\em omp parallel for schedule (dynamic)} e {\em omp 
parallel for schedule (static)}. As diferenças de funcionamento dos 
dois códigos está na maneira em que o trabalho é dividido e como ele é
distribuido para cada thread.

\subsection{Implementação com Divisão Estática}
Chamamos de implementação com divisão estática a versão do nosso 
código em pthreads no qual o trabalho é dividido em $n$ pedaços de mesmo 
tamanho, e cada pedaço é dado a uma thread. Chamamos essa implementação
de estática porque cada thread recebe apenas um bloco de trabalho,
pré-determinado pela divisão feita, que será processado do começo ao
fim (no escopo da thread) pela mesma thread.

Para implementar esse código, precisamos apenas construir uma estrutura
de dados que era capaz de guardar um bloco de pixels a ser calculado.
Dado essa estrutura, basta criar uma thread para cada bloco de trabalho,
que por sua vez deve calcular os pixels correspondentes e atualizar o 
buffer de cores.

Devemos observar que essa implementação pode implicar em threads ociosas
enquanto outras estão trabalhando. Como a quantidade de iterações
necessárias para se calcular o valor de um pixel varia, é possível que
um bloco de pixels seja calculado muito mais rápido do que outro; 
imagine por exemplo um bloco onde cada ponto calculado diverge 
rápidamente e outro bloco onde isso não acontece. Portanto, como a 
divisão de trabalho é estática, é provável que uma thread termine seu
trabalho muito antes de outra, o que significa em um uso não muito bom
de recursos da máquina.

Uma possível solução para esse problema seria o aumento no número de 
threads, o que cria uma fragmentação maior do trabalho. Essa 
fragmentação ameniza o problema anterior porque divide mais o trabalho,
deixando menor a diferença de tempo necessário para se calcular cada 
parte. Entretanto, criar um número excessivo de threads pode dar mais
trabalho ao escalonador do sistema operacional, que deve lidar com 
várias linhas de processamento.

\begin{figure}[!ht]
    \centering
    \begin{tabular}{c c}
        \subfigure[] {\scalebox{.35}{
            \includegraphics{time_x_thread_numpth_sta_n512.png}}
            \label {fig:higher_thread_num:A}
        }
        &
        \subfigure[] {\scalebox{.35}{
            \includegraphics{time_x_thread_numpth_sta_n2048.png}}
            \label {fig:higher_thread_num:B}
        }

    \end{tabular}
    \caption{É possível notar em ambas figuras que o aumento do número
    de threads de fato diminui o tempo de execução do programa. No 
    gráfico \ref{fig:higher_thread_num:A} fica evidente que o tempo 
    gasto no controle das threads pode afetar o tempo de execução do
    programa.}
    \label{fig:higher_thread_num} 
\end{figure}

\subsection{Implementação com Divisão Dinâmica}
A implementação dinâmica do nosso programa também divide o trabalho em
$n$ pedaços, entretanto agora $n$ não é mais, necessariamente o número
de threads disponíveis. Após dividir o trabalho em pedaços, o nosso 
programa agora é capaz de, dinâmicamente, delegar blocos de pixels a 
cada thread. Portanto, agora diminuimos o problema de threads ociosas,
porque podemos dividir mais os blocos de trabalho e sempre que uma 
thread termina um bloco, podemos dar a ela um novo bloco para computar 
(desde que ainda haja trabalho a ser feito).

Veja abaixo um pseudo-código para esse programa:
\begin{algorithmic}[1]
\Function{ComputeMandelbrot}{}
    \State $S \gets $ lista de nacos de todos os pixels
    \While{$S \neq \emptyset$}
        \State $chunk \gets S$.popChunk ()
        \State Espere {\em alguma} thread estar livre
        \ForAll{Threat $T$}
            \If{$T$ está livre}
                \State $T$.compute ($chunk$)
            \EndIf
        \EndFor
    \EndWhile 
    \EndFunction
\end{algorithmic}

A implementação desse código é um pouco mais complicada, porque depende,
além da estrutura de dados já usada na implementação estática, de um 
maior controle de concorrência. O conceito principal utilizado é o de 
{\em condition variable}, que nos permite colocar a linha principal de
execução em espera, enquanto as threads calculam os pixels, para voltar
a ser executada quando alguma thread estiver livre.

Diminuido o problema de threads ociosas, é esperado que essa 
implementação seja mais rápida do que a anterior, porém, é necessário 
notar que o nosso código ficou mais complexo, e exige mais recursos
<<<<<<< HEAD
computacionais para o controle das threads. Esse tempo pode ser 
prejudicial se o tamanho do chunk for pequeno, pois nessa situação
há muitas trocas de chunks em cada thread, fazendo com que a maior parte
do tempo de processamento seja gasto no controle das threads. Por outro
lado, se temos chunks grandes o tempo gasto deve aumentar, porque caímos
novamente no problema da implementação static, onde o trabalho não era
bem dividido.

\begin{figure}[!ht]
    \centering
    \begin{tabular}{c c}
        \subfigure[] {\scalebox{.35}{
            \includegraphics{time_x_chunk_sizepth2048elephant.png}}
            \label {fig:pthreads_chunk_size:A}
        }
        &
        \subfigure[] {\scalebox{.35}{
        \includegraphics{time_x_chunk_sizepth2048seahorse_valley.png}
        }
            \label {fig:pthreads_chunk_size:B}
        }
        \\
        \subfigure[] {\scalebox{.35}{
            \includegraphics{time_x_chunk_sizepth2048triple_spiral.png}}
            \label {fig:pthreads_chunk_size:C}
        }
        &
        \subfigure[] {\scalebox{.35}{
            \includegraphics{time_x_chunk_sizepth2048full.png}}
            \label {fig:pthreads_chunk_size:D}
        }
        
    \end{tabular}
    \caption{Verificamos empiricamente que definir o tamanho do chunk 
        como  o tamanho do lado da imagem traz bons resultados para o
        tempo de execução.}
    \label{fig:pthreads_chunk_size} 
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=.5]{time_x_thread_numpth.png}
\end{figure}


=======
<<<<<<< HEAD
computacionais para o controle das threads.
\newpage
>>>>>>> 5c630943e627b170add9c5c09bd54df8dbc9748c

\newpage
\section{Código em OpenMP}
Outra API usada na paralelização é o OpenMP. Pela natureza do cálculo do conjunto Mandelbrot, como cada iteração possui tempo de execução diferente para cada pixel, utilizamos \textit{dynamic scheduling}, sendo ela que oferece melhor distribuição de trabalho.


\begin{figure}[!ht]
    \centering
    \begin{tabular}{c c}
        \subfigure[] {\scalebox{.35}{
            \includegraphics{omp_all/time_threads_all.png}}
            \label {fig:omp_all:A}
        }
        &
        \subfigure[] {\scalebox{.35}{
        \includegraphics{omp_all/time_threads_all_minor_values.png}}
            \label {fig:omp_all:B}
        }
    \end{tabular}
    \caption{Observamos .}
    \label{fig:omp_all} 
\end{figure}

Há um aumento de tempo de execução no cálculo do conjunto de regiões ampliadas como *spiral*, *elephant* devido ao maior número de cálculos envolvidos em uma região ampliada do nosso conjunto.
\begin{figure}[!ht]
    \centering
    \begin{tabular}{c c}
        \subfigure[] {\scalebox{.35}{
            \includegraphics{omp_full/time_input_omp_minor_values.png}}
            \label {fig:omp_full:A}
        }
        &
        \subfigure[] {\scalebox{.35}{
        \includegraphics{omp_full/time_input_omp.png}}
            \label {fig:omp_full:B}
        }
        \\
        \subfigure[] {\scalebox{.35}{
            \includegraphics{omp_full/time_thread_omp_minor_values.png}}
            \label {fig:omp_full:C}
        }
        &
        \subfigure[] {\scalebox{.35}{
            \includegraphics{omp_full/time_thread_omp.png}}
            \label {fig:omp_full:D}
        }
        
    \end{tabular}
    \caption{Temos a comparação de execução entre as 4 regiões do conjunto.}
    \label{fig:omp_full} 
\end{figure}

\newpage
<<<<<<< HEAD



=======
=======
computacionais para o controle das threads. Esse tempo pode ser 
prejudicial se o tamanho do chunk for pequeno, pois nessa situação
há muitas trocas de chunks em cada thread, fazendo com que a maior parte
do tempo de processamento seja gasto no controle das threads. Por outro
lado, se temos chunks grandes o tempo gasto deve aumentar, porque caímos
novamente no problema da implementação static, onde o trabalho não era
bem dividido.

\begin{figure}[!ht]
    \centering
    \begin{tabular}{c c}
        \subfigure[] {\scalebox{.35}{
            \includegraphics{time_x_chunk_sizepth2048elephant.png}}
            \label {fig:pthreads_chunk_size:A}
        }
        &
        \subfigure[] {\scalebox{.35}{
        \includegraphics{time_x_chunk_sizepth2048seahorse_valley.png}
        }
            \label {fig:pthreads_chunk_size:B}
        }
        \\
        \subfigure[] {\scalebox{.35}{
            \includegraphics{time_x_chunk_sizepth2048triple_spiral.png}}
            \label {fig:pthreads_chunk_size:C}
        }
        &
        \subfigure[] {\scalebox{.35}{
            \includegraphics{time_x_chunk_sizepth2048full.png}}
            \label {fig:pthreads_chunk_size:D}
        }
        
    \end{tabular}
    \caption{Verificamos empiricamente que definir o tamanho do chunk 
        como  o tamanho do lado da imagem traz bons resultados para o
        tempo de execução.}
    \label{fig:pthreads_chunk_size} 
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=.5]{time_x_thread_numpth.png}
\end{figure}

>>>>>>> 4653e6a4273fd2c776556871f4cc6a77b068e828
>>>>>>> 5c630943e627b170add9c5c09bd54df8dbc9748c
\section{Conclusão}
\end{document}
